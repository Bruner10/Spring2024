---
title: "Homework 2"
author: "Jonathan Bruner"
date: "`r Sys.Date()`"
output: html_document
---

<br><br>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(MASS)
library(e1071)
library(pROC)
library(lattice)
library(ISLR2)
library(class)
```

## Question 1: Chapter 4 Exercise 6

Suppose we collect data for a group of students in a statistics class with variables $X_1=\text{hours studied}$, $X_2=\text{undergrad GPA}$, and $Y=\text{receive an A}$. We fit a logistic regression and produce estimated coefficient, $\hat{\beta}_0=-6$, $\hat{\beta}_1=0.05$, $\hat{\beta}_2=1$.

#### (a) Estimate the probability that a student who studies for 40 hours and has an undergrad GPA of 3.5 gets an A in the class.

```{r}
y = 0.05*40 + 1*3.5 + (-6)

ans = exp(y) / (1 + exp(y))
```

The estimated probability is: $p(x)=P(Y=1|X_1=40,X_2=3.5)=$ `r ans` $=$ `r ans*100`%.

<br>

#### (b) How many hours would the student in part (a) need to study to have a 50% chance of getting an A in the class?

```{r}
logodds = log(0.5/(1 - 0.5))

x_1 = ((logodds - (-6) - (1 * 3.5)) / 0.05)
```

The student from part (a) would need to study for `r x_1` hours to have a 50% chance of getting an A in the class, according to our model.

<br><br>

***

## Question 2

This question uses the **iris** data set which contains information related to flower measurements for three different species of iris. You do not need to create training and test sets for this problem.


#### (a) Create a new data frame called **iris2** by removing all of the setosa species flowers from the original data set.

```{r}
iris2 = iris[which(iris$Species != 'setosa'),]
iris2 = droplevels(iris2)
```

<br>

#### (b) Fit a logistic regression model on the data to predict species using the other variables.

```{r}
fit1_lrm = glm(Species ~ ., data=iris2, family='binomial')
pred1_lrm = predict(fit1_lrm, iris2, type='response')

pred1_lrm_values = rep("versicolor", dim(iris2)[1])
pred1_lrm_values[pred1_lrm > 0.5] = "virginica"

table(iris2$Species, pred1_lrm_values)

lrm_sens = mean(iris2$Species == pred1_lrm_values)
lrm_sens
```

<br>

#### (c) Repeat part (b) using LDA.

```{r}
fit1_lda = lda(Species ~ ., data=iris2)
pred1_lda = predict(fit1_lda, iris2)

table(iris2$Species, pred1_lda$class)

lda_sens = mean(iris2$Species == pred1_lda$class)
lda_sens
```

<br>

#### (d) Repeat part (b) using QDA.

```{r}
fit1_qda = qda(Species ~ ., data=iris2)
pred1_qda = predict(fit1_qda, iris2)

table(iris2$Species, pred1_qda$class)

qda_sens = mean(iris2$Species == pred1_qda$class)
qda_sens
```

<br>

#### (e) Repeat part (b) using naive Bayes.

```{r}
fit1_nb = naiveBayes(Species ~ ., data=iris2)
pred1_nb = predict(fit1_nb, iris2, type='raw')

pred1_nb_values = predict(fit1_nb, iris2)

table(iris2$Species, pred1_nb_values)

nb_sens = mean(iris2$Species == pred1_nb_values)
nb_sens
```

<br>

#### (f) Which model performs best? Justify your conclusion with appropriate statistics.

```{r, message=FALSE}
plot.roc(Species ~ pred1_lrm, asp=NA, data=iris2, col='green')
plot.roc(Species ~ pred1_lda$posterior[,1], asp=NA, data=iris2, add=TRUE, col='blue')
plot.roc(Species ~ pred1_qda$posterior[,1], asp=NA, data=iris2, add=TRUE, col='red')
plot.roc(Species ~ pred1_nb[,1], asp=NA, data=iris2, add=TRUE, col='orange')

legend('bottomright', 
       legend=c('Linear Regression','Linear Discriminant','Quadratic Discriminant','Naive Bayes'), 
       col=c('green','blue','red','orange'), 
       lty=1)
```

Based off of the Graphs along with the measures of sensitivity I would say that the Linear Regression Model is the one that performs the best.

<br>

#### (g) Which model had the highest sensitivity?

```{r}
if (max(lrm_sens, lda_sens, qda_sens, nb_sens) == lrm_sens){
  print(paste('The Linear Regression Model has the highest sensitivity with', lrm_sens))
} else if (max(lrm_sens, lda_sens, qda_sens, nb_sens) == lda_sens){
  print(paste('The Linear Discriminant Analysis Model has the highest sensitivity with', lda_sens))
} else if (max(lrm_sens, lda_sens, qda_sens, nb_sens) == qda_sens){
  print(paste('The Quadratic Discriminant Analysis Model has the highest sensitivity with', qda_sens))
} else if (max(lrm_sens, lda_sens, qda_sens, nb_sens) == nb_sens){
  print(paste('The Naive Bayes Model has the highest sensitivity with', nb_sens))
}
```

<br>

#### (h) Does it seem reasonable to use LDA and QDA with this data? Do some investigating and explain why or why not.

```{r, fig.height=8, fig.width=8}
super.sym = trellis.par.get("superpose.symbol")
splom(~iris[1:4], groups = Species, data = iris2,
      key = list(title = "Two Varieties of Iris",
                 columns = 2, 
                 points = list(pch = super.sym$pch[1:2],
                 col = super.sym$col[1:2]),
                 text = list(c("Versicolor", "Virginica"))))
```

From the above graphs it appears that the assumption of a linear decision boundary is good rather than a quadratic decision boundary, so that tells me that QDA might not be the most reasonable model. Since this question limits the data to using a binary response variable, it would be most reasonable to use LRM over LDA. If we were to use the full **iris** dataset, LDA would be the most reasonable model to use.

<br><br>

***

## Question 3

A statistician fits a logistic regression model to classify a binary response variable using one predictor variable. You know that $P(Y=1|X=4)=0.88877$ and $P(Y=0|X=6)=0.96562$. Use this information to find the estimated values of $\beta_0$ and $\beta_1$.

$$log(\frac{0.88877}{1-0.88877})=\beta_0+4\beta_1$$

$$log(\frac{1-0.96562}{0.96562})=\beta_0+6\beta_1$$

```{r}
a = matrix(c(1,1,4,6), nrow = 2, ncol = 2)
b = c(log(0.88877/(1-0.88877)), log((1-0.96562)/0.96562))

solution = solve(a,b)
```

$\beta_0=$ `r solution[1]`

$\beta_1=$ `r solution[2]`

<br><br>

***

## Question 4: Chapter 4 Exercise 14

For parts (d)-(g) use cylinders, displacement, horsepower, weight, and acceleration, and also remove the original mpg variable from the dataset.

In this problem, you will develop a model to predict whether a given car gets high or low gas mileage based on the ***Auto*** data set.

#### (a) Create a binary variable, *mpg01*, that contains a 1 if *mpg* contains a value above its median, and a 0 if *mpg* contains a value below its median. You can compute the median using the **median()** function. Note you may find it helpful to use the **data.frame()** function to create a single data set containing both *mpg02* and the other ***Auto*** variables.

```{r}
# Get data from the Auto dataset
# Removing mpg, name, and origin columns
dat4 = Auto[,c(-1,-8,-9)]

# Factorize variables
dat4$year = as.factor(dat4$year)

# Create binary response variable based on mpg
dat4$mpg01 = rep(1,nrow(dat4))
dat4[which(Auto$mpg < median(Auto$mpg)),'mpg01'] = 0
dat4$mpg01 = as.factor(dat4$mpg01)
```

<br>

#### (b) Explore the data graphically in order to investigate the association between *mpg01* and the other features. Which of the other features seem most likely to be useful in predicting *mpg01*? Scatterplots and boxplots may be useful tools to answer this question. Describe your findings.

```{r, fig.height=9, fig.width=9}
super.sym = trellis.par.get("superpose.symbol")
splom(~dat4[1:ncol(dat4)-1], groups = mpg01, data = dat4,
      key = list(title = "Median MPG",
                 columns = 2, 
                 points = list(pch = super.sym$pch[1:2],
                 col = super.sym$col[1:2]),
                 text = list(c("0: Below the Median MPG", "1: Above the Median MPG"))))
```

```{r, fig.height=9, fig.width=9}
par(mfrow = c(2,3))

for (i in 1:(ncol(dat4)-1)) {
  boxplot(dat4[,i] ~ dat4[,7], xlab='mpg01', ylab=colnames(dat4)[i])
}
```

From the above plots it appears that *displacement*, *weight*, *cylinders*, and *horsepower* are the 4 best predictor variables.

<br>

#### (c) Split the data into a training set and a test set.

```{r}
set.seed(1)

# Create 80/20 split between train and test data
train = sample(1:nrow(dat4), round(.8*nrow(dat4)))

train_dat4 = dat4[train,]
test_dat4 = dat4[-train,]
```

<br>

#### (d) Perform LDA on the training data in order to predict *mpg01* using the variables that seemed most associated with *mpg01* in (b). What is the test error of the model obtained?

```{r}
fit4_lda = lda(mpg01 ~ cylinders + displacement + horsepower + weight + acceleration,
               data=train_dat4)
pred4_lda = predict(fit4_lda, test_dat4)

pred4_lda_conf_matrx = table(test_dat4$mpg01, pred4_lda$class)
pred4_lda_conf_matrx
```

<br>

#### (e) Perform QDA on the training data in order to predict *mpg01* using the variables that seemed most associated with *mpg01* in (b). What is the test error of the model obtained?

```{r}
fit4_qda = qda(mpg01 ~ cylinders + displacement + horsepower + weight + acceleration,
               data=train_dat4)
pred4_qda = predict(fit4_qda, test_dat4)

pred4_qda_conf_matrx = table(test_dat4$mpg01, pred4_qda$class)
pred4_qda_conf_matrx
```

<br>

#### (f) Perform logistic regression on the training data in order to predict *mpg01* using the variables that seemed most associated with *mpg01* in (b). What is the test error of the model obtained?

```{r}
fit4_lrm = glm(mpg01 ~ cylinders + displacement + horsepower + weight + acceleration,
               data=train_dat4, family='binomial')
pred4_lrm = predict(fit4_lrm, test_dat4, type='response')

pred4_lrm_values = rep("0", nrow(test_dat4))
pred4_lrm_values[pred4_lrm > 0.5] = "1"

pred4_lrm_conf_matrx = table(test_dat4$mpg01, pred4_lrm_values)
pred4_lrm_conf_matrx
```

<br>

#### (g) Perform naive Bayes on the training data in order to predict *mpg01* using the variables that seemed most associated with *mpg01* in (b). What is the test error of the model obtained?

```{r}
fit4_nb = naiveBayes(mpg01 ~ cylinders + displacement + horsepower + weight + acceleration,
               data=train_dat4)
pred4_nb = predict(fit4_nb, test_dat4)

pred4_nb_conf_matrx = table(test_dat4$mpg01, pred4_nb)
pred4_nb_conf_matrx
```

<br>

#### (h) Perform KNN on the training data, with several values K, in order to predict *mpg01*. Use only the variables that seemed most associated with *mpg01* in (b). What test errors do you obtain? Which value of K seems to perform the best on this data set?

```{r}
train_dat4_x = train_dat4[,1:(ncol(train_dat4)-1)]
train_dat4_y = train_dat4[,ncol(train_dat4)]
test_dat4_x = test_dat4[,1:(ncol(test_dat4)-1)]
test_dat4_y = test_dat4[,ncol(test_dat4)]

max_k = ifelse(ceiling(sqrt(nrow(train_dat4))) %% 2 == 0, ceiling(sqrt(nrow(train_dat4))), floor(sqrt(nrow(train_dat4))))

model_performance = data.frame('K_value'= double(), 'Test_Error'= double())

loop_range = seq(from=1, to=max_k, by=2)
for (i in loop_range) {
  
  fit4_knn = knn(train_dat4_x, test_dat4_x, train_dat4_y, k=i)
  fit4_knn_conf_matrix = table(test_dat4_y, fit4_knn)
  
  j = which(loop_range == i)
  
  model_performance[j,1] = i
  model_performance[j,2] = (fit4_knn_conf_matrix[1,2] + fit4_knn_conf_matrix[2,1]) / sum(fit4_knn_conf_matrix)
  
}

model_performance
```

The following values of K result in the lowest Test Error: `r model_performance[which(model_performance$Test_Error == min(model_performance$Test_Error)),1]`. For simplicity since the test errors are the same I would choose `r model_performance[which(model_performance$Test_Error == min(model_performance$Test_Error)),1][1]` as my value for K.

<br><br>

***

## Question 5: Chapter 4 Exercise 15

#### (a) Write a function, **Power()**, that prints out the result of raising 2 to the 3rd power. In other words, your function should compute $2^3$ and print out the results.

```{r}
Power = function(){
  print(2^3)
}

Power()
```

<br>

#### (b) Create a new function, **Power2()**, that allows you to pass *any* two numbers, x and a, and prints out the value of $x^a$.

```{r}
Power2 = function(x, a){
  print(x^a)
}

Power2(3, 8)
```

<br>

#### (c) Using the **Power2()** function that you just wrote, compute $10^3$, $8^17$, and $131^3$.

```{r}
Power2(10,3)
Power2(8,17)
Power2(131,3)
```

<br>

#### (d) Now create a new function, **Power3()**, that actually *returns* the result $x^a$ as an R object, rather than simply printing it to the screen. That is, if you store the value $x^a$ in an object called result within your function, then you can simply return() this result.

```{r}
Power3 = function(x, a){
  result = x^a
  return(result)
}

Power3(2,2)
```

<br>

#### (e) Now using the **Power3()** function, create a plot of $f(x)=x^2$. The x-axis should display a range of integers from 1 to 10, and the y-axis should display $x^2$. Label the axes appropiately, and use an appropriate title for the figure. Consider displaying either the x-axis, the y-axis, or both on the log-scale.

```{r}
plot(seq(1,10,.01),Power3(seq(1,10,.01),2),log='y',xlab='x',ylab='log(x^2)',pch='.',xaxp=c(1,10,9), main='f(x) = log(x^2)')
```

<br>

#### (f) Create a function, **PlotPower()**, that allows you to create a plot of x against $x^a$ for a fixed a and for a range of values of x.

```{r}
PlotPower = function(x, a){
  
  len_x = length(x)
  
  plot(seq(x[1],x[len_x],.01), Power3(seq(x[1],x[len_x],.01),2), log='y', main=paste('f(x) = log(x^',a,')', sep=''),
       xlab='x', ylab=paste('log(x^',a,')', sep=''), pch='.', xaxp=c(x[1],x[len_x],len_x-1))
  
}

PlotPower(1:15,3)
```

<br><br>